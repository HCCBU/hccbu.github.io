

@inproceedings{Rigby-et-al-Poster-VIS2023,
	author = {Rigby, Alex and Butcher, Peter W.S. and Roberta Bellini and Coughlan, Paul and Mc Nabola, Aonghus and Ritsos, Panagiotis D. },
	title = {{DUVis: A visual analytics tool for supporting a trans-disciplinary project}},
	year = {2023},
	month = oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2023), Melbourne, Australia},
	abstract={We present DUVis, a visual analytics application developed to support the analysis and appraisal, of the transdiciplinary project Dŵr Uisce, from internal project managers and external stakeholders. DUVis provides a number of visualizations and additional features to facilitate data exploration of a project's progress. It presents a map of stakeholders' activities, and their engagement with each other, as well as outputs, workpackages, their completion status and potential impact. We present our preliminary design and provide a blueprint for further development.},
	
}



@inproceedings{Roberts-et-al-Poster-VIS2023,
	author = {Roberts, Jonathan C. and  Alnjar, Hannan, and Owen, Aron E, and Ritsos, Panagiotis D.},
	title = {{A method for Critical and Creative Visualisation Design-Thinking}},
	year = {2023},
	month = oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2023), Melbourne, Australia},
	abstract={Visualisation design requires critical thought: to understand important facets, investigate design suitability and explore alternatives. But, especially for learners, it can be difficult to structure a critical reflection of creative solutions. We introduce the Critical Design Survey (CDS): structured method that facilitates visualisation design analysis through reflective and critical thought. Applying the CDS helps someone to structure critical thought, provides a unified method that can be readily taught, learners can actively engage with the process and directly use it to write a critical-thinking report of their design ideas. The CDS contains three steps: Step 1, summarise and write down the essence of the idea. Step 2, perform an in-depth critique (we define 30 questions structured in six perspectives). Step 3, synthesise the ideas, implications, and decide on the next steps. We present the CDS, describe our design process (critical thinking workshops, talk aloud, and student use), and describe our use in teaching visualisation to undergraduate and postgraduate students.},

}





@inproceedings{Bellini-et-al-Poster-EGU2023,
	author = {Roberta Bellini and Coughlan, Paul and Bello-Dambatta, Aisha and Rigby, Alex and Ritsos, Panagiotis D. and Mc Nabola, Aonghus},
	title = {{An interactive visualisation tool to manage metadata in engaged research projects, track progress, map stakeholders, and evaluate output, outcomes and impacts,}},
	year = {2023},
	month = apr,
	booktitle = {EGU General Assembly, Vienna, Austria},
	doi = {10.5194/egusphere-egu23-2630},
	url={https://meetingorganizer.copernicus.org/EGU21/EGU21-4139.html},
	abstract={This paper presents the research management experience of a multi-disciplinary team and their reflections on how they responded to these challenges and implemented working solutions. As a team from five disciplines, we reflect on this shared experience gained over a 6.5 year-long EU-funded project. Stimulated by the project complexity, we came to recognise that how we managed the data provided us with an opportunity to collaborate meaningfully and to link in novel ways the contributions of research activities to the outcomes and impacts of the project. In brief, we devised a new research data management approach through which we collated and visualised the data so as to facilitate deeper exploration of the interactions among the researchers, tasks and deliverables.}
}





@inproceedings{Rigby-et-al-Poster-WDNA-2022,
	author = {Rigby, Alex M.F. and Butcher, Peter W.S. and Patil, Sopan D. and Ritsos, Panagiotis D.},
	title = {{Using AI and big data to optimise land management decisions for reducing river flood risk}},
	year = {2022},
	month = may,
	booktitle = {Data Transformation: Wales Data Nations Accelerator, Cardiff, UK},
	nopaper={true},
	abstract={Local authorities across Wales are increasingly seeking natural approaches to river flood management, especially the role of land management decisions in reducing peak flows. Physics-based hydrological models, which simulate river flood response to storm events, can provide multi-scenario assessment of land-use changes on floods. However, they require prior calibration of parameters using measured streamflow data, which is not available for many rivers. We investigate how AI and big data can be used to implement hydrological models in river basins with no streamflow data.}
}



@inproceedings{Rigby-et-al-Poster-EGU-2021,
	author = {Rigby, Alex and Patil, Sopan and Ritsos, Panagiotis D.},
	title = {{A novel toolkit to streamline Land Use Land Cover change assessment in the SWAT+ model to enhance flood management and infrastructure decisions}},
	year = {2021},
	month = apr,
	booktitle = {EGU General Assembly 2021, online event},
	doi = {10.5194/egusphere-egu21-4139},
	url={https://meetingorganizer.copernicus.org/EGU21/EGU21-4139.html},
	abstract={Land Use Land Cover (LULC) change is widely recognised as one of the most important factors impacting river basin hydrology.  It is therefore imperative that the hydrological impacts of various LULC changes are considered for effective flood management strategies and future infrastructure decisions within a catchment.  The Soil and Water assessment Tool (SWAT) has been used extensively to assess the hydrological impacts of LULC change.  Areas with assumed homogeneous hydrologic properties, based on their LULC, soil type and slope, make up the basic computational units of SWAT known as the Hydrologic Response Units (HRUs).  LULC changes in a catchment are typically modelled by SWAT through alterations to the input files that define the properties of these HRUs.  However, to our knowledge at least, the process of making such changes to the SWAT input files is often cumbersome and non-intuitive.  This affects the useability of SWAT as a decision support tool amongst a wider pool of applied users (e.g., engineering teams in environmental regulatory agencies and local authorities).  In this study, we seek to address this issue by developing a user-friendly toolkit that will: (1) allow the end user to specify, through a Graphical User Interface (GUI), various types of LULC changes at multiple locations within their study catchment, (2) run the SWAT+ model (the latest version of SWAT) with the specified LULC changes, and (3) enable interactive visualisation of the different SWAT+ output variables to quantify the hydrological impacts of these scenarios.  Importantly, our toolkit does not require the end user to have any operational knowledge of the SWAT+ model to use it as a decision support tool.  Our toolkit will be trialled at 15 catchments in Gwynedd county, Wales, which has experienced multiple occurrences of high flood events, and consequent economic damage, in the recent past.  We anticipate this toolkit to be a valuable addition to the decision-making processes of Gwynedd County Council for the planning and development of future flood alleviation schemes as well as other infrastructure projects.}
}


@inproceedings{Williams-et-al-VIS-2020,
	author = {Williams, Rhys L. and Farmer, Dan and Roberts, Jonathan C., and Ritsos, Panagiotis D.},
	title = {{Immersive visualisation of COVID-19 UK travel and US happiness data}},
	year = {2020},
	month = oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2020), Virtual Event},
	url={http://ieeevis.org/year/2020/welcome},
	dposter={https://vis2020-ieee.ipostersessions.com/default.aspx?s=9C-2F-4C-7F-0B-3B-AE-97-4F-11-DA-1A-54-5D-58-62},
	abstract={The global COVID-19 pandemic has had great affect on the lives of everyone, from changing how children are educated to how or whether at all, we travel, go to work or do our shopping. Consequently, not only has people’s happiness changed throughout the pandemic, but there has been less vehicles on the roads. We present work to visualise both US happiness and UK travel data, as examples, in immersive environments. These impromptu visualisations encourage discussion and engagement with these topics, and can help people see the data in an alternative way.}
}







@inproceedings{Jackson-et-al-Poster-VIS2018,
	author = {Jackson, James and Ritsos, Panagiotis D. and Roberts, Jonathan C.},
	title = {{Creating Small Unit Based Glyph Visualisations}},
	year = {2018},
	month = oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2018), Berlin, Germany},
	url={http://ieeevis.org/year/2018/welcome},
	vmpreview={290331312},
	abstract={Many modern day tasks involve the use of small screens, where users want to see a summary visualisation of an activity. For example, a runner using a smart watch needs to quickly view their progress, heart rate, comparison to previous races, etc. Subsequently, there is a need to portray data to users in small, yet well-defined, spaces. We define this space to be a single self-contained ``unit''. In this paper we introduce a glyph visualisation algorithm that creates a diverse range of visualisation designs; each design contains many separate parts, whereupon different parameters can be mapped. Our algorithm uses a path based approach which allows designers to create deterministic, yet unique designs, in a unit space to display multivariate data.}
}


@inproceedings{Butcher-et-al-Poster-VIS2018,
	author = {Butcher, Peter W.S. and John, Nigel W. and Ritsos, Panagiotis D.},
	title = {{Towards a Framework for Immersive Analytics on the Web}},
	year = {2018},
	month = oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2018), Berlin, Germany},
	url={http://ieeevis.org/year/2018/welcome},
	vmpreview={290331695},
	abstract={We present work-in-progress on the design and implementation of a Web framework for building Immersive Analytics (IA) solutions in Virtual Reality (VR). We outline the design of our prototype framework, VRIA, which facilitates the development of VR spaces for IA solutions, which can be accessed via a Web browser. VRIA is built on emerging open-standards Web technologies such as WebVR, A-Frame and React, and supports a variety of interaction devices (e.g., smartphones, head-mounted displays etc.). We elaborate on our motivation for focusing on open-standards Web technologies and provide an overview of our framework. We also present two early visualization components. Finally, we outline further extensions and investigations.}
}


@inproceedings{Ritsos-et-al-Poster-VIS2017,
	author = {Ritsos, Panagiotis D. and Jackson, James and Roberts, Jonathan C.},
	title = {{Web-based Immersive Analytics in Handheld Augmented Reality}},
	year = {2017},
	month=oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2017), Phoenix, Arizona, USA},
	url={http://ieeevis.org/},
	vmpreview={230838347},
	abstract={The recent popularity of virtual reality (VR), and the emergence of a number of affordable VR interfaces, have prompted researchers and developers to explore new, immersive ways to visualize data. This has resulted in a new research thrust, known as Immersive Analytics (IA). However, in IA little attention has been given to the paradigms of augmented/mixed reality (AR/MR), where computer-generated and physical objects co-exist. In this work, we explore the use of contemporary web-based technologies for the creation of immersive visualizations for handheld AR, combining D3.js with the open standards-based Argon AR framework and A-frame/WebVR. We argue in favor of using emerging standards-based web technologies as they work well with contemporary visualization tools, that are purposefully built for data binding and manipulation.},
}


@inproceedings{Butcher-et-al-Poster-VIS2016,
	author = {Butcher, Peter W.S. and Roberts, Jonathan C. and Ritsos, Panagiotis D.},
	title = {{Immersive Analytics with WebVR and Google Cardboard}},
	year = {2016},
	month=oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2016), Baltimore, MD, USA},
	url={http://ieeevis.org/year/2016/info/vis-welcome/welcome},
	vmpreview={182985336},
	abstract={We present our initial investigation of a low-cost, web-based virtual reality platform for immersive analytics, using a Google Cardboard, with a view of extending to other similar platforms such as Samsung’s Gear VR. Our prototype uses standards-based emerging frameworks, such as WebVR and explores some the challenges faced by developers in building effective and informative immersive 3D visualizations, particularly those that attempt to resemble recent physical visualizations built in the community.}
}



@inproceedings{Roberts-et-al-Poster-VIS2016,
	author = {Roberts, Jonathan C. and Jackson, James. and Headleand, Chris and Ritsos, Panagiotis D.},
	title = {{Creating Explanatory Visualizations of Algorithms for Active Learning}},
	year = {2016},
	month=oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2016), Baltimore, MD, USA},
	url={http://ieeevis.org/year/2016/info/vis-welcome/welcome},
	vmpreview={182984932},
	abstract={Visualizations have been used to explain algorithms to learners, in order to help them understand complex processes. These ‘explanatory visualizations’ can help learners understand computer algorithms and data-structures. But most are created by an educator and merely watched by the learner. In this paper, we explain how we get learners to plan and develop their own explanatory visualizations of algorithms. By actively developing their own visualizations learners gain a deeper insight of the algorithms that they are explaining. These depictions can also help other learners understand the algorithm.}
}

@inproceedings{Gray-et-al-Poster-VIS2015,
	author = {Gray, Cameron C. and Roberts, Jonathan C. and Ritsos, Panagiotis D.},
	title = {{Where Can I Go From Here? Drawing Contextual Navigation Maps of the London Underground}},
	year = {2015},
	month=oct,
	booktitle = {Posters presented at the IEEE Conference on Visualization (IEEE VIS 2015), Chicago, IL, USA},
	url={http://ieeevis.org/year/2015/info/vis-welcome/welcome},
	vmpreview={136252426},
	abstract={Network administrators often wish to ascertain where network attackers are located; therefore it would be useful to display the network map from the context of either the attacker’s potential location or the attacked host. As part of a bigger project we are investigating how to best visualize contextual network data. We use a dataset of station adjacencies with journey times as edge weights, to explore which visualization design is most suitable, and also ascertain the best network shortest-path metric. This short paper presents our initial findings, and a visualization for Contextual Navigation using circular, centered-phylogram projections of the network. Our visualizations are interactive allowing users to explore different scenarios and observe relative distances in the data.}
}


@inproceedings{Headleand-et-al-Poster-VCBM2015,
	booktitle ={Eurographics Workshop on Visual Computing for Biology and Medicine},
	editor ={Katja B\"uhler and Lars Linsen and Nigel W. John},
	title ={Challenges and Technologies for Low Cost Wheelchair Simulation},
	author ={Headleand, Christopher J. and Day, Thomas and Pop, Serban R. and Ritsos, Panagiotis D. and John, Nigel W.},
	year ={2015},
	month=sep,
	publisher ={The Eurographics Association},
	url={http://www.vcbm.org/previous-workshops/vcbm-2015/},
	doi={10.2312/vcbm.20151225},
	abstract={The use of electric wheelchairs is inherently risky, as collisions due to lack of control can result in injury for the user, but also potentially for other pedestrians. Introducing new users to powered chairs via virtual reality (VR) provides one possible solution, as it eliminates the risks inherent to the real world during training. However, traditionally simulator technology has been too expensive to make VR a financially viable solution. Also, current simulators lack the natural interaction possible in the real world, limiting their operational value. We present the early stages of a VR, electric wheelchair simulator built using low-cost, consumer level gaming hardware. The simulator makes use use of the the Leap Motion, to provide a level of interaction with the virtual world which has not previously been demonstrated in wheelchair training simulators. Furthermore, the Occulous Rift provides an immersive experience suitable for our training application}
}

@inproceedings{Ritsos-et-al-Poster-VCBM2015,
	booktitle ={Eurographics Workshop on Visual Computing for Biology and Medicine},
	editor ={Katja B\"uhler and Lars Linsen and Nigel W. John},
	title ={A Haptics-enabled Simulator for Transperineal Ultrasound-Guided Biopsy},
	author ={Ritsos, Panagiotis D. and Edwards, Marc R. and Shergill, Iqbal S. and John, Nigel W.},
	year ={2015},
	month=sep,
	publisher ={The Eurographics Association},
	url={http://www.vcbm.org/previous-workshops/vcbm-2015/},
	doi={10.2312/vcbm.20151229},
	abstract={We present the development of a transperineal prostate biopsy, with high fidelity haptic feedback. We describe our current prototype, which is using physical props and a Geomagic Touch. In addition, we discuss a method for collecting in vitro axial needle forces, for programming haptic feedback, along with implemented an forthcoming features such as a display of 2D ultrasonic images for targeting, biopsy needle bending, prostate bleeding and calcification. Our ultimate goal is to provide an affordable high-fidelity simulation by integrating contemporary off-the-shelf technology components.},
}



@inproceedings{Roberts-et-al-Poster-VIS2014,
	author ={Jonathan C. Roberts and Rick T. Walker and Lukas Roberts and Robert S. Laramee and Panagiotis D Ritsos},
	title ={Exploratory Visualization through Copy, Cut and Paste},
	year ={2014},
	booktitle ={Posters presented at the IEEE Conference on Visualization (VIS), November 9-14, Paris, France},
	month=nov,
	url={http://ieeevis.org/year/2014/info/vis-welcome/welcome},
	vmpreview={103142940},
	abstract={Our goal is to help oceanographers to visualize and navigate their data over several runs. We have been using parallel coordinate plots to display every data value. Through our copy, cut, paste interactions we aim to enable users to drill-down into specific data points and to explore the datasets in a more expressive way. The method allows users to manipulate the PCP on a ZUI canvas, take copies of the current PCP and paste different subset views.}
}



@inproceedings{George-et-al-Poster-EuroVis2014,
	author ={George, Richard L.S.F. and Ritsos, Panagiotis D. and Roberts, Jonathan C.},
	title ={Interactive Oceanographic Visualization using spatially-aggregated Parallel Coordinate Plots},
	year ={2014},
	booktitle ={Posters presented at EuroVis 2014, June 9-13 , Swansea, Wales, UK},
	month=jun,
	url={http://eurovis.swansea.ac.uk/},
	preview={http://pdritsos.com/files/poster-RGeorgeInteractive.mp4},
	abstract={Visual Analytics interfaces allow ocean scientists to interactively investigate and compare different runs and parameterizations. However, oceanographic models are complex, temporal and the datasets that are generated are huge. Parallel Coordinate Plots can help explore multivariate data such as ocean-science data. Common issues with traditional PCPs of clutter and performance inhibit interactive spatial exploration. We describe techniques that aggregates the PCP based on the spatial nature of the data and we render the polylines as ranges.}
}


@inproceedings{Ritsos-et-al-Poster-VIS2013,
	author ={Ritsos, Panagiotis D. and Pan\"eels, Sabrina A. and Rodgers, Peter J. and Roberts, Jonathan C.},
	title ={Towards a Formalized Process for Creating Haptic Data Visualizations},
	year ={2013},
	month=oct,
	booktitle ={Posters presented at the IEEE Conference on Visualization (VIS), October 15-18, Atlanta, Georgia, USA},
	url={http://ieeevis.org/year/2013/info/vis-welcome/welcome},
	preview={http://pdritsos.com/files/poster-RitsosHDV.mp4},
	abstract={Haptic Data Visualization (HDV) is a novel application of haptics. It provides functionality by which users touch and feel data, making it a useful tool for users with vision impairments. However, creating such visualizations usually requires programming knowledge, that support workers and tutors of blind users may not possess. To address this issue we propose a formalized process for creating HDVs using the HITPROTO [5] toolkit, which requires no programming experience. We further illustrate this process using an example HDV.}
}


@inproceedings{Roberts-et-al-VANATO,
	author = { Roberts, Jonathan C. and ap Cenydd, Llyr and Ritsos,
	Panagiotis D. and George, Richard and Teahan, William and Walker, Rick},
	title = {{Visual Analytics with Storyboarding to engender multivocality and comprehension of Microblog data for Crisis Management}},
	booktitle = {The Information Systems Technology Panel Symposium on Visual Analytics (IST-116/RSY-028), Shrivenham, UK},
	location = {Shrivenham, UK},
	month = oct,
	year = {2013}
}
